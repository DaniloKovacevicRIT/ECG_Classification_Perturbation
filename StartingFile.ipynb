{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:39:59.146227Z",
     "start_time": "2025-11-10T04:39:37.846677Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from perturbations import PerturbationConfig, apply_perturbation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e66144f72e5b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:39:59.156964Z",
     "start_time": "2025-11-10T04:39:59.147763Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd11e0fda3eea56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:09.616760Z",
     "start_time": "2025-11-10T04:39:59.159316Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'ptb-xl/'\n",
    "sampling_rate=100\n",
    "\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "# Train\n",
    "X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "\n",
    "# Test\n",
    "X_test = X[np.where(Y.strat_fold == test_fold)]\n",
    "y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adf2a6cf9bb191",
   "metadata": {},
   "source": [
    "### Fixing Y data for proper training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7ee6015e2e4eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:09.666933Z",
     "start_time": "2025-11-10T04:53:09.616760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels (y_encoded):\n",
      " [[0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " ...\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]]\n",
      "\n",
      "Class Names (Order of Columns):\n",
      " ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train_enc = mlb.fit_transform(y_train)\n",
    "y_test_enc = mlb.fit_transform(y_test)\n",
    "print(\"Encoded Labels (y_encoded):\\n\", y_train_enc)\n",
    "print(\"\\nClass Names (Order of Columns):\\n\", mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4887129641c5137b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef6cf187928b36",
   "metadata": {},
   "source": [
    "## Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0e1dbdd972c9ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:10.044573Z",
     "start_time": "2025-11-10T04:53:09.669267Z"
    }
   },
   "outputs": [],
   "source": [
    "# THis is the number of classes. For Superclass it will be 5, if we do all of or a subset of the subclasses there can be more or less.\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# The input shape for the dataset\n",
    "IN_SHAPE = (1000,12)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(IN_SHAPE),\n",
    "    Conv1D(filters=32, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    # Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='sigmoid')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17407136d288d6",
   "metadata": {},
   "source": [
    "## Compiling and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94fc9ba5c56856e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:10.076413Z",
     "start_time": "2025-11-10T04:53:10.046602Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', # could also use categorical_crossentropy here for a single choice per input. Change output to softmax if doing that approach though\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(multi_label=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89908e413d8cd081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:36.205368Z",
     "start_time": "2025-11-10T04:53:10.078066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m613/613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.5970 - auc_1: 0.8336 - loss: 0.3910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e219365730>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960152a6effb3a40",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2816b6d2b9a04553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:37.862230Z",
     "start_time": "2025-11-10T04:53:36.207541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6146 - auc_1: 0.8715 - loss: 0.3614\n",
      "Test Loss: 0.3614\n",
      "Test Accuracy: 0.6146\n",
      "Test AUC: 0.8715\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, auc_score = model.evaluate(X_test, y_test_enc, verbose=1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f292c95",
   "metadata": {},
   "source": [
    "## Noise Robustness Evaluation\n",
    "\n",
    "We compare model performance on clean signals versus signals with band-limited noise applied\n",
    "through the perturbation API (strength = 0.3). Adjust the configuration to explore different artefacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7b32877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Clean evaluation ===\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6146 - auc_1: 0.8715 - loss: 0.3614\n",
      "Clean -> Loss: 0.3614, Acc: 0.6146, AUC: 0.8715\n",
      "=== Noisy evaluation ===\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6106 - auc_1: 0.8714 - loss: 0.3625\n",
      "Noisy -> Loss: 0.3625, Acc: 0.6106, AUC: 0.8714\n"
     ]
    }
   ],
   "source": [
    "noise_seed = 42\n",
    "noise_config = PerturbationConfig(\n",
    "    ptype='band_noise',\n",
    "    strength=1,\n",
    "    center_time=5.0,\n",
    "    window_seconds=None,\n",
    "    extra={'beta': 0.1, 'band': (5.0, 40.0)}\n",
    ")\n",
    "\n",
    "def evaluate_clean_and_noisy(model, X_eval, y_eval, fs, noise_cfg, seed=None):\n",
    "    rng = np.random.default_rng(seed) if seed is not None else None\n",
    "    print('=== Clean evaluation ===')\n",
    "    clean_metrics = model.evaluate(X_eval, y_eval, verbose=1)\n",
    "    print(f'Clean -> Loss: {clean_metrics[0]:.4f}, Acc: {clean_metrics[1]:.4f}, AUC: {clean_metrics[2]:.4f}')\n",
    "    print('=== Noisy evaluation ===')\n",
    "    X_noisy = np.stack([\n",
    "        apply_perturbation(x, fs=fs, config=noise_cfg, rng=rng)\n",
    "        for x in X_eval\n",
    "    ])\n",
    "    noisy_metrics = model.evaluate(X_noisy, y_eval, verbose=1)\n",
    "    print(f'Noisy -> Loss: {noisy_metrics[0]:.4f}, Acc: {noisy_metrics[1]:.4f}, AUC: {noisy_metrics[2]:.4f}')\n",
    "    return clean_metrics, noisy_metrics, X_noisy\n",
    "\n",
    "clean_metrics, noisy_metrics, X_test_noisy = evaluate_clean_and_noisy(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test_enc,\n",
    "    fs=sampling_rate,\n",
    "    noise_cfg=noise_config,\n",
    "    seed=noise_seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378dec410ddc601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:53:37.868782Z",
     "start_time": "2025-11-10T04:53:37.864417Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
